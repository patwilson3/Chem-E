{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def resize_frame(frame, scale_percent=30):\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(frame, (width, height))\n",
    "\n",
    "def analyze_region(frame, x, y, width, sig=15):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    x = max(0, min(x, frame_width - width))\n",
    "    y = max(0, min(y, frame_height - width))\n",
    "    \n",
    "    roi = frame[y:y+width, x:x+width].copy()\n",
    "    blurred_roi = cv2.GaussianBlur(roi, (25,25), 0)\n",
    "    \n",
    "    # Quantize colors to reduce subtle variations\n",
    "    # Divide by 16 and multiply back to reduce color space\n",
    "    quantized_roi = (blurred_roi // 16) * 16\n",
    "    \n",
    "    lab_roi = cv2.cvtColor(blurred_roi, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    pixel_vals = quantized_roi.reshape((-1, 3)).astype(np.float32)\n",
    "    \n",
    "    # More stringent criteria for convergence\n",
    "    # Increased epsilon from 10 to 30 to require more significant difference\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1)\n",
    "    n_clusters = 5\n",
    "    \n",
    "    # Add minimum distance between cluster centers\n",
    "    min_distance = 30 # Adjust this value to control sensitivity\n",
    "    \n",
    "    while True:\n",
    "        _, labels, centers = cv2.kmeans(pixel_vals, n_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "        \n",
    "        # Check distances between all pairs of center\n",
    "        centers_valid = True\n",
    "        for i in range(len(centers)):\n",
    "            for j in range(i + 1, len(centers)):\n",
    "                dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                if dist < min_distance:\n",
    "                    centers_valid = False\n",
    "                    break\n",
    "            if not centers_valid:\n",
    "                break\n",
    "                \n",
    "        if centers_valid:\n",
    "            break\n",
    "            \n",
    "        # If centers are too close, reduce number of clusters\n",
    "        n_clusters -= 1\n",
    "        if n_clusters < 1:\n",
    "            n_clusters = 1\n",
    "            break\n",
    "    #if n_clusters > 1:\n",
    "     #   sil_score = silhouette_score(pixel_vals, labels=labels.flatten())\n",
    "    \n",
    "    #print(f\"sil_score: {sil_score}\")\n",
    "    #count pixel frequency per label\n",
    "    counts = np.bincount(labels.flatten())\n",
    "    # Increased threshold from 0.20 to 0.25 to require more significant color regions\n",
    "    print(f\"pixelvals: {len(pixel_vals)}\")\n",
    "    #significant cluster if it occupies greater than 10% of total pixels in frame\n",
    "    significant_clusters = np.sum(counts > len(pixel_vals) * .10)\n",
    "    \n",
    "    centers = np.uint8(centers)\n",
    "    segmented_data = centers[labels.flatten()]\n",
    "    segmented_image = segmented_data.reshape(roi.shape)\n",
    "\n",
    "    #print(f\"Significant_clusters: {significant_clusters}, x: {x}, y: {y}\")\n",
    "    \n",
    "    return significant_clusters, x, y, roi, blurred_roi, lab_roi, segmented_image\n",
    "\n",
    "def visualize_processing_steps(frame, res_x, res_y, roi, blurred_roi, lab_roi, distinct_colors, kmeans_output, window_name=\"Processing Steps\"):\n",
    "    \n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    roi_height, roi_width = roi.shape[:2]\n",
    "\n",
    "    vis_width = frame_width * 6 \n",
    "    visualization = np.zeros((frame_height, vis_width, 3), dtype=np.uint8)\n",
    "\n",
    "    frame_with_roi = frame.copy()\n",
    "    cv2.rectangle(frame_with_roi, \n",
    "                  (res_x, res_y),\n",
    "                  (res_x + roi_width - 1, res_y + roi_height - 1),\n",
    "                  (0, 0, 255), 2)  # Highlight square ROI\n",
    "    visualization[:, :frame_width] = frame_with_roi\n",
    "\n",
    "    roi_section = visualization[:, frame_width:frame_width * 2]\n",
    "    roi_resized = cv2.resize(roi, (frame_width, frame_height))\n",
    "    roi_section[:frame_height, :] = roi_resized\n",
    "\n",
    "    gaussian_section = visualization[:, frame_width*2:frame_width * 3]\n",
    "    gaussian_resized = cv2.resize(blurred_roi, (frame_width, frame_height))\n",
    "    gaussian_section[:frame_height, :] = gaussian_resized\n",
    "\n",
    "    lab_section = visualization[:, frame_width * 3:frame_width * 4]\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_roi)\n",
    "    l_norm = cv2.normalize(l_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    a_norm = cv2.normalize(a_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    b_norm = cv2.normalize(b_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    lab_visual = cv2.merge([l_norm, a_norm, b_norm])\n",
    "    lab_resized = cv2.resize(lab_visual, (frame_width, frame_height))\n",
    "    lab_section[:frame_height, :] = lab_resized\n",
    "\n",
    "    variation_section = visualization[:, frame_width * 4:frame_width * 5]\n",
    "    lab_variation = np.std(lab_roi, axis=2)\n",
    "    lab_variation = cv2.normalize(lab_variation, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    variation_map = cv2.applyColorMap(lab_variation.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    variation_resized = cv2.resize(variation_map, (frame_width, frame_height))\n",
    "    variation_section[:frame_height, :] = variation_resized\n",
    "\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "\n",
    "    # Modified section for kmeans visualization\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "    # Get unique colors and their positions from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    for color in unique_colors:\n",
    "        # Find positions where this color appears\n",
    "        mask = np.all(kmeans_resized == color, axis=2)\n",
    "        positions = np.where(mask)\n",
    "        if len(positions[0]) > 0:\n",
    "            # Calculate center of mass for this color\n",
    "            y_center = int(np.mean(positions[0]))\n",
    "            x_center = int(np.mean(positions[1]))\n",
    "            # Draw circle at the center position\n",
    "            center_pos = (frame_width * 5 + x_center, y_center)\n",
    "            cv2.circle(visualization, center_pos, 5, (255, 255, 255), -1)  # White fill\n",
    "            cv2.circle(visualization, center_pos, 5, (0, 0, 0), 1)  # Black border\n",
    "\n",
    "    # Modified section for kmeans visualization\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "    # Get unique colors and their positions from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    centers = []  # Store centers for drawing connections\n",
    "    \n",
    "    # First pass: find and draw centers\n",
    "    for color in unique_colors:\n",
    "        # Find positions where this color appears\n",
    "        mask = np.all(kmeans_resized == color, axis=2)\n",
    "        positions = np.where(mask)\n",
    "        if len(positions[0]) > 0:\n",
    "            # Calculate center of mass for this color\n",
    "            y_center = int(np.mean(positions[0]))\n",
    "            x_center = int(np.mean(positions[1]))\n",
    "            center_pos = (frame_width * 5 + x_center, y_center)\n",
    "            centers.append(center_pos)\n",
    "            # Draw circle at the center position\n",
    "            cv2.circle(visualization, center_pos, 5, (255, 255, 255), -1)  # White fill\n",
    "            cv2.circle(visualization, center_pos, 5, (0, 0, 0), 1)  # Black border\n",
    "    \n",
    "    # Second pass: draw lines and distances between centers\n",
    "    for i in range(len(centers)):\n",
    "        for j in range(i + 1, len(centers)):\n",
    "            center1 = centers[i]\n",
    "            center2 = centers[j]\n",
    "            # Calculate Euclidean distance\n",
    "            distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "            # Draw line between centers\n",
    "            cv2.line(visualization, center1, center2, (0, 255, 0), 1)\n",
    "            # Calculate midpoint for text\n",
    "            mid_x = (center1[0] + center2[0]) // 2\n",
    "            mid_y = (center1[1] + center2[1]) // 2\n",
    "            # Draw distance value\n",
    " \n",
    "            cv2.putText(visualization, f'{distance:.1f}', (mid_x, mid_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)  # Black text\n",
    "\n",
    "    # Draw color centers as circles in the bottom right corner of kmeans section\n",
    "    center_size = 30\n",
    "    spacing = 40\n",
    "    start_x = frame_width * 5 + 20\n",
    "    start_y = frame_height - 40\n",
    "\n",
    "    # Get unique colors from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    \n",
    "    # Draw circles for each center color\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        x = start_x + i * spacing\n",
    "        cv2.circle(visualization, (x, start_y), center_size // 2, color.tolist(), -1)\n",
    "        # Draw white border around circle\n",
    "        cv2.circle(visualization, (x, start_y), center_size // 2, (255, 255, 255), 1)\n",
    "        # Add distance to nearest center if more than one center exists\n",
    "        if len(unique_colors) > 1:\n",
    "            distances = [np.linalg.norm(color - other_color) for other_color in unique_colors if not np.array_equal(color, other_color)]\n",
    "            min_dist = min(distances)\n",
    "            cv2.putText(visualization, f'{min_dist:.0f}', (x - 10, start_y + 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.7\n",
    "    font_thickness = 2\n",
    "    def add_text_with_background(img, text, pos):\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "        cv2.rectangle(img, \n",
    "                      (pos[0] - 5, pos[1] - text_height - baseline - 5),\n",
    "                      (pos[0] + text_width + 5, pos[1] + 5),\n",
    "                      (0, 0, 0), -1)\n",
    "        cv2.putText(img, text, pos, font, font_scale, (255, 255, 255), font_thickness)\n",
    "\n",
    "    add_text_with_background(visualization, 'Original Frame', (10, 30))\n",
    "    add_text_with_background(visualization, 'ROI', (frame_width + 10, 30))\n",
    "    add_text_with_background(visualization, 'Gaussian', (frame_width * 2 + 10, 30))\n",
    "    add_text_with_background(visualization, 'LAB Space', (frame_width * 3 + 10, 30))\n",
    "    add_text_with_background(visualization, 'Color Variation', (frame_width * 5 + 10, 30))\n",
    "    add_text_with_background(visualization, f'KMeans Output (Colors: {distinct_colors})', (frame_width * 4 + 10, 30))\n",
    "\n",
    "    cv2.imshow(window_name, visualization)\n",
    "    cv2.waitKey(1)\n",
    "    return visualization\n",
    "\n",
    "def detect_color_change(video_path, scale_percent=30, buffer_size=9, threshold=0.7, save_interval=30):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return None, None\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if ret:\n",
    "        print(f\"Initial frame shape: {first_frame.shape}\")\n",
    "        scaled_shape = resize_frame(first_frame, scale_percent).shape\n",
    "        print(f\"Scaled frame shape: {scaled_shape}\")\n",
    "        roi_height = int(scaled_shape[0] * 0.2)\n",
    "        print(f\"Expected ROI height: {roi_height}\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to start\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_interval = max(1, int(fps / 5))\n",
    "    expected_samples = total_frames // frame_interval\n",
    "    \n",
    "    print(f\"\\nVideo information:\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Original FPS: {fps:.1f}\")\n",
    "    print(f\"Analyzing every {frame_interval}th frame (3Hz)\")\n",
    "    print(f\"Expected samples: {expected_samples}\")\n",
    "    \n",
    "    color_counts = deque(maxlen=buffer_size)\n",
    "    frame_number = 0\n",
    "    samples_processed = 0\n",
    "    last_update_time = time.time()\n",
    "    last_save_time = time.time()\n",
    "    os.makedirs('processing_steps', exist_ok=True)\n",
    "    sig = -1\n",
    "    \n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_number += 1\n",
    "            \n",
    "            if frame_number % frame_interval != 0:\n",
    "                continue\n",
    "            \n",
    "            samples_processed += 1\n",
    "            current_time = time.time()\n",
    "\n",
    "            small_frame = resize_frame(frame, scale_percent)\n",
    "            denoised = cv2.fastNlMeansDenoisingColored(small_frame, None, 5, 5, 3, 9)\n",
    "\n",
    "            distinct_colors, res_x, res_y, roi, blurred_roi, lab_roi, kmeans_output = analyze_region(denoised, x=310, y=50, width=260, sig=sig)\n",
    "            color_counts.append(distinct_colors)\n",
    "            print(f\"color_counts : {color_counts}\")\n",
    "            vis = visualize_processing_steps(denoised, res_x, res_y, roi, blurred_roi, lab_roi, distinct_colors, kmeans_output)\n",
    "            \n",
    "            if current_time - last_save_time > save_interval:\n",
    "                save_path = f'processing_steps/frame_{frame_number}.jpg'\n",
    "                cv2.imwrite(save_path, vis)\n",
    "                last_save_time = current_time\n",
    "            \n",
    "            if current_time - last_update_time > 2:\n",
    "                progress = (frame_number / total_frames) * 100\n",
    "                elapsed_time = current_time - last_update_time\n",
    "                samples_per_second = samples_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "                print(f\"Progress: {progress:.1f}% (Frame {frame_number}/{total_frames}, \"\n",
    "                      f\"Processing rate: {samples_per_second:.1f} Hz)\")\n",
    "                samples_processed = 0\n",
    "                last_update_time = current_time\n",
    "            \n",
    "            if len(color_counts) == buffer_size:\n",
    "                #np.mean(color_counts)\n",
    "                #avg_colors = np.median(color_counts)\n",
    "                avg_colors = np.bincount(color_counts)\n",
    "                #avg_colors < 2\n",
    "                if avg_colors[2] == buffer_size:\n",
    "                    timestamp = frame_number / fps\n",
    "                    print(f\"\\nColor change detected!\")\n",
    "                    print(f\"Frame: {frame_number}/{total_frames} ({(frame_number/total_frames)*100:.1f}%)\")\n",
    "                    print(f\"Timestamp: {timestamp:.2f} seconds\")\n",
    "                    print(f\"Avg number of colors: {avg_colors}\")\n",
    "                    print(f\"color_counts: {color_counts}\")\n",
    "                    print(f\"\")\n",
    "                    \n",
    "                    # Save final detection frame\n",
    "                    cv2.imwrite('processing_steps/detection_frame.jpg', vis)\n",
    "                    \n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return frame_number, timestamp\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        raise\n",
    "    \n",
    "    print(\"\\nProcessing complete - No clear color change point detected\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"testresults_jan24th.txt\", \"a\")\n",
    "path = os.open(\"TODO\")\n",
    "\n",
    "for video in path:\n",
    "    frame_number, timestamp = detect_color_change(video)\n",
    "    file.write(f\"Frame number: {frame_number}, timestamp: {timestamp}, Video: {video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def resize_frame(frame, scale_percent=30):\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(frame, (width, height))\n",
    "\n",
    "def analyze_region(frame, x, y, width, threshold, clusters, min_distance):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    x = max(0, min(x, frame_width - width))\n",
    "    y = max(0, min(y, frame_height - width))\n",
    "    \n",
    "    roi = frame[y:y+width, x:x+width].copy()\n",
    "    blurred_roi = cv2.GaussianBlur(roi, (25,25), 0)\n",
    "    \n",
    "    # Quantize colors to reduce subtle variations\n",
    "    # Divide by 16 and multiply back to reduce color space\n",
    "    quantized_roi = (blurred_roi // 16) * 16\n",
    "    \n",
    "    lab_roi = cv2.cvtColor(blurred_roi, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    pixel_vals = quantized_roi.reshape((-1, 3)).astype(np.float32)\n",
    "    \n",
    "    # More stringent criteria for convergence\n",
    "    # Increased epsilon from 10 to 30 to require more significant difference\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1)\n",
    "    n_clusters = clusters\n",
    "    \n",
    "    # Add minimum distance between cluster centers\n",
    "    #min_distance = 30 # Adjust this value to control sensitivity\n",
    "    \n",
    "    while True:\n",
    "        _, labels, centers = cv2.kmeans(pixel_vals, n_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "        \n",
    "        # Check distances between all pairs of center\n",
    "        centers_valid = True\n",
    "        for i in range(len(centers)):\n",
    "            for j in range(i + 1, len(centers)):\n",
    "                dist = np.linalg.norm(centers[i] - centers[j])\n",
    "                if dist < min_distance:\n",
    "                    centers_valid = False\n",
    "                    break\n",
    "            if not centers_valid:\n",
    "                break\n",
    "                \n",
    "        if centers_valid:\n",
    "            break\n",
    "            \n",
    "        # If centers are too close, reduce number of clusters\n",
    "        n_clusters -= 1\n",
    "        if n_clusters < 1:\n",
    "            n_clusters = 1\n",
    "            break\n",
    "    \n",
    "    #count pixel frequency per label\n",
    "    counts = np.bincount(labels.flatten())\n",
    "    # Increased threshold from 0.20 to 0.25 to require more significant color regions\n",
    "    #print(f\"pixelvals: {len(pixel_vals)}\")\n",
    "    #significant cluster if it occupies greater than 10% of total pixels in frame\n",
    "    significant_clusters = np.sum(counts > len(pixel_vals) * threshold)\n",
    "    \n",
    "    centers = np.uint8(centers)\n",
    "    segmented_data = centers[labels.flatten()]\n",
    "    segmented_image = segmented_data.reshape(roi.shape)\n",
    "\n",
    "    #print(f\"Significant_clusters: {significant_clusters}, x: {x}, y: {y}\")\n",
    "    \n",
    "    return significant_clusters, x, y, roi, blurred_roi, lab_roi, segmented_image\n",
    "\n",
    "def visualize_processing_steps(frame, res_x, res_y, roi, blurred_roi, lab_roi, distinct_colors, kmeans_output, window_name=\"Processing Steps\"):\n",
    "    \n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    roi_height, roi_width = roi.shape[:2]\n",
    "\n",
    "    vis_width = frame_width * 6 \n",
    "    visualization = np.zeros((frame_height, vis_width, 3), dtype=np.uint8)\n",
    "\n",
    "    frame_with_roi = frame.copy()\n",
    "    cv2.rectangle(frame_with_roi, \n",
    "                  (res_x, res_y),\n",
    "                  (res_x + roi_width - 1, res_y + roi_height - 1),\n",
    "                  (0, 0, 255), 2)  # Highlight square ROI\n",
    "    visualization[:, :frame_width] = frame_with_roi\n",
    "\n",
    "    roi_section = visualization[:, frame_width:frame_width * 2]\n",
    "    roi_resized = cv2.resize(roi, (frame_width, frame_height))\n",
    "    roi_section[:frame_height, :] = roi_resized\n",
    "\n",
    "    gaussian_section = visualization[:, frame_width*2:frame_width * 3]\n",
    "    gaussian_resized = cv2.resize(blurred_roi, (frame_width, frame_height))\n",
    "    gaussian_section[:frame_height, :] = gaussian_resized\n",
    "\n",
    "    lab_section = visualization[:, frame_width * 3:frame_width * 4]\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_roi)\n",
    "    l_norm = cv2.normalize(l_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    a_norm = cv2.normalize(a_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    b_norm = cv2.normalize(b_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    lab_visual = cv2.merge([l_norm, a_norm, b_norm])\n",
    "    lab_resized = cv2.resize(lab_visual, (frame_width, frame_height))\n",
    "    lab_section[:frame_height, :] = lab_resized\n",
    "\n",
    "    variation_section = visualization[:, frame_width * 4:frame_width * 5]\n",
    "    lab_variation = np.std(lab_roi, axis=2)\n",
    "    lab_variation = cv2.normalize(lab_variation, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    variation_map = cv2.applyColorMap(lab_variation.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    variation_resized = cv2.resize(variation_map, (frame_width, frame_height))\n",
    "    variation_section[:frame_height, :] = variation_resized\n",
    "\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "\n",
    "    # Modified section for kmeans visualization\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "    # Get unique colors and their positions from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    for color in unique_colors:\n",
    "        # Find positions where this color appears\n",
    "        mask = np.all(kmeans_resized == color, axis=2)\n",
    "        positions = np.where(mask)\n",
    "        if len(positions[0]) > 0:\n",
    "            # Calculate center of mass for this color\n",
    "            y_center = int(np.mean(positions[0]))\n",
    "            x_center = int(np.mean(positions[1]))\n",
    "            # Draw circle at the center position\n",
    "            center_pos = (frame_width * 5 + x_center, y_center)\n",
    "            cv2.circle(visualization, center_pos, 5, (255, 255, 255), -1)  # White fill\n",
    "            cv2.circle(visualization, center_pos, 5, (0, 0, 0), 1)  # Black border\n",
    "\n",
    "    # Modified section for kmeans visualization\n",
    "    kmeans_section = visualization[:, frame_width * 5:frame_width * 6]\n",
    "    kmeans_resized = cv2.resize(kmeans_output, (frame_width, frame_height))\n",
    "    kmeans_section[:frame_height, :] = kmeans_resized\n",
    "\n",
    "    # Get unique colors and their positions from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    centers = []  # Store centers for drawing connections\n",
    "    \n",
    "    # First pass: find and draw centers\n",
    "    for color in unique_colors:\n",
    "        # Find positions where this color appears\n",
    "        mask = np.all(kmeans_resized == color, axis=2)\n",
    "        positions = np.where(mask)\n",
    "        if len(positions[0]) > 0:\n",
    "            # Calculate center of mass for this color\n",
    "            y_center = int(np.mean(positions[0]))\n",
    "            x_center = int(np.mean(positions[1]))\n",
    "            center_pos = (frame_width * 5 + x_center, y_center)\n",
    "            centers.append(center_pos)\n",
    "            # Draw circle at the center position\n",
    "            cv2.circle(visualization, center_pos, 5, (255, 255, 255), -1)  # White fill\n",
    "            cv2.circle(visualization, center_pos, 5, (0, 0, 0), 1)  # Black border\n",
    "    \n",
    "    # Second pass: draw lines and distances between centers\n",
    "    for i in range(len(centers)):\n",
    "        for j in range(i + 1, len(centers)):\n",
    "            center1 = centers[i]\n",
    "            center2 = centers[j]\n",
    "            # Calculate Euclidean distance\n",
    "            distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "            # Draw line between centers\n",
    "            cv2.line(visualization, center1, center2, (0, 255, 0), 1)\n",
    "            # Calculate midpoint for text\n",
    "            mid_x = (center1[0] + center2[0]) // 2\n",
    "            mid_y = (center1[1] + center2[1]) // 2\n",
    "            # Draw distance value\n",
    " \n",
    "            cv2.putText(visualization, f'{distance:.1f}', (mid_x, mid_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)  # Black text\n",
    "\n",
    "    # Draw color centers as circles in the bottom right corner of kmeans section\n",
    "    center_size = 30\n",
    "    spacing = 40\n",
    "    start_x = frame_width * 5 + 20\n",
    "    start_y = frame_height - 40\n",
    "\n",
    "    # Get unique colors from kmeans output\n",
    "    unique_colors = np.unique(kmeans_output.reshape(-1, 3), axis=0)\n",
    "    \n",
    "    # Draw circles for each center color\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        x = start_x + i * spacing\n",
    "        cv2.circle(visualization, (x, start_y), center_size // 2, color.tolist(), -1)\n",
    "        # Draw white border around circle\n",
    "        cv2.circle(visualization, (x, start_y), center_size // 2, (255, 255, 255), 1)\n",
    "        # Add distance to nearest center if more than one center exists\n",
    "        if len(unique_colors) > 1:\n",
    "            distances = [np.linalg.norm(color - other_color) for other_color in unique_colors if not np.array_equal(color, other_color)]\n",
    "            min_dist = min(distances)\n",
    "            cv2.putText(visualization, f'{min_dist:.0f}', (x - 10, start_y + 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.7\n",
    "    font_thickness = 2\n",
    "    def add_text_with_background(img, text, pos):\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "        cv2.rectangle(img, \n",
    "                      (pos[0] - 5, pos[1] - text_height - baseline - 5),\n",
    "                      (pos[0] + text_width + 5, pos[1] + 5),\n",
    "                      (0, 0, 0), -1)\n",
    "        cv2.putText(img, text, pos, font, font_scale, (255, 255, 255), font_thickness)\n",
    "\n",
    "    add_text_with_background(visualization, 'Original Frame', (10, 30))\n",
    "    add_text_with_background(visualization, 'ROI', (frame_width + 10, 30))\n",
    "    add_text_with_background(visualization, 'Gaussian', (frame_width * 2 + 10, 30))\n",
    "    add_text_with_background(visualization, 'LAB Space', (frame_width * 3 + 10, 30))\n",
    "    add_text_with_background(visualization, 'Color Variation', (frame_width * 4 + 10, 30))\n",
    "    add_text_with_background(visualization, f'KMeans Output (Colors: {distinct_colors})', (frame_width * 5 + 10, 30))\n",
    "\n",
    "    cv2.imshow(window_name, visualization)\n",
    "    cv2.waitKey(1)\n",
    "    return visualization\n",
    "\n",
    "def detect_color_change(video_path, scale_percent=30, buffer_size=9, threshold=0.7, save_interval=30, clusters=7, min_distance=20):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return None, None\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if ret:\n",
    "        print(f\"Initial frame shape: {first_frame.shape}\")\n",
    "        scaled_shape = resize_frame(first_frame, scale_percent).shape\n",
    "        print(f\"Scaled frame shape: {scaled_shape}\")\n",
    "        roi_height = int(scaled_shape[0] * 0.2)\n",
    "        print(f\"Expected ROI height: {roi_height}\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to start\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_interval = max(1, int(fps / 5))\n",
    "    expected_samples = total_frames // frame_interval\n",
    "    \n",
    "    '''\n",
    "    print(f\"\\nVideo information:\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Original FPS: {fps:.1f}\")\n",
    "    print(f\"Analyzing every {frame_interval}th frame (3Hz)\")\n",
    "    print(f\"Expected samples: {expected_samples}\")'''\n",
    "    \n",
    "    color_counts = deque(maxlen=buffer_size)\n",
    "    frame_number = 0\n",
    "    samples_processed = 0\n",
    "    last_update_time = time.time()\n",
    "    last_save_time = time.time()\n",
    "    os.makedirs('processing_steps', exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_number += 1\n",
    "            \n",
    "            if frame_number % frame_interval != 0:\n",
    "                continue\n",
    "            \n",
    "            samples_processed += 1\n",
    "            current_time = time.time()\n",
    "\n",
    "            small_frame = resize_frame(frame, scale_percent)\n",
    "            denoised = cv2.fastNlMeansDenoisingColored(small_frame, None, 5, 5, 3, 9)\n",
    "\n",
    "            distinct_colors, res_x, res_y, roi, blurred_roi, lab_roi, kmeans_output = analyze_region(denoised, x=310, y=50, width=260, threshold=threshold, clusters=clusters, min_distance=min_distance)\n",
    "            color_counts.append(distinct_colors)\n",
    "            #print(f\"color_counts : {color_counts}\")\n",
    "            #vis = visualize_processing_steps(denoised, res_x, res_y, roi, blurred_roi, lab_roi, distinct_colors, kmeans_output)\n",
    "            \n",
    "            if current_time - last_save_time > save_interval:\n",
    "                #save_path = f'processing_steps/frame_{frame_number}.jpg'\n",
    "                #cv2.imwrite(save_path, vis)\n",
    "                last_save_time = current_time\n",
    "            \n",
    "            if current_time - last_update_time > 2:\n",
    "                progress = (frame_number / total_frames) * 100\n",
    "                elapsed_time = current_time - last_update_time\n",
    "                samples_per_second = samples_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "                #print(f\"Progress: {progress:.1f}% (Frame {frame_number}/{total_frames}, \"\n",
    "                     # f\"Processing rate: {samples_per_second:.1f} Hz)\")\n",
    "                samples_processed = 0\n",
    "                last_update_time = current_time\n",
    "            \n",
    "            if len(color_counts) == buffer_size:\n",
    "                #np.mean(color_counts)\n",
    "                avg_colors = np.median(color_counts)\n",
    "                avg_colors = np.bincount(color_counts)\n",
    "                #avg_colors < 2\n",
    "                if avg_colors[2] == buffer_size:\n",
    "                    timestamp = frame_number / fps\n",
    "                    print(f\"\\nColor change detected!\")\n",
    "                    print(f\"Frame: {frame_number}/{total_frames} ({(frame_number/total_frames)*100:.1f}%)\")\n",
    "                    print(f\"Timestamp: {timestamp:.2f} seconds\")\n",
    "                    print(f\"Avg number of colors: {avg_colors}\")\n",
    "                    print(f\"color_counts: {color_counts}\")\n",
    "                    print(f\"\")\n",
    "                    \n",
    "                    # Save final detection frame\n",
    "                    #cv2.imwrite('processing_steps/detection_frame.jpg', vis)\n",
    "                    \n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return frame_number, timestamp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        raise\n",
    "    \n",
    "    #print(\"\\nProcessing complete - No clear color change point detected\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return -1, -1\n",
    "\n",
    "\n",
    "#things we want to modify: % significant cluster (10-30), n_clusters (4-8), min_distance(10-50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
